{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251835\n",
      "27981\n",
      "279816\n"
     ]
    }
   ],
   "source": [
    "# w合并人造数据集\n",
    "import json\n",
    "df1 = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/extend_data/SIGHAN_Wang271K/train.json', \n",
    "                'r', encoding='utf-8'))\n",
    "print(len(df1))\n",
    "df2 = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/extend_data/SIGHAN_Wang271K/dev.json', \n",
    "                'r', encoding='utf-8'))\n",
    "print(len(df2))\n",
    "\n",
    "dfe = df1+df2\n",
    "print(len(dfe))\n",
    "for sample in dfe:\n",
    "    sample[\"id\"] = -1\n",
    "    sample[\"source\"] = sample.pop(\"original_text\")\n",
    "    sample[\"target\"] = sample.pop(\"correct_text\")\n",
    "    sample[\"type\"] = \"positive\" if len(sample.pop(\"wrong_ids\"))==0 else \"negative\"\n",
    "df = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_train.json', \n",
    "                'r', encoding='utf-8'))\n",
    "dfe = df+dfe\n",
    "print(len(dfe))\n",
    "with open('/148Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_train_with_wang271k.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(dfe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n"
     ]
    }
   ],
   "source": [
    "# 创建stage3的finetune数据集\n",
    "import json\n",
    "df3 = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/extend_data/SIGHAN_Wang271K/test.json', \n",
    "                'r', encoding='utf-8'))\n",
    "print(len(df3))\n",
    "for sample in df3:\n",
    "    sample[\"source\"] = sample.pop(\"original_text\")\n",
    "    sample[\"target\"] = sample.pop(\"correct_text\")\n",
    "    sample[\"type\"] = \"positive\" if len(sample.pop(\"wrong_ids\"))==0 else \"negative\"\n",
    "with open('/148Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_train_stage3.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(df3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/148_Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_extend_train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7590/2113728060.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 创建preliminary_extend_train_with_val.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m df1 = json.load(open('/148_Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_extend_train.json', \n\u001b[0m\u001b[1;32m      4\u001b[0m                 'r', encoding='utf-8'))\n\u001b[1;32m      5\u001b[0m df2 = json.load(open('/148_Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_val.json', \n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/148_Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_extend_train.json'"
     ]
    }
   ],
   "source": [
    "# 创建preliminary_extend_train_with_val.json\n",
    "import json\n",
    "df1 = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_extend_train.json', \n",
    "                'r', encoding='utf-8'))\n",
    "df2 = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_val.json', \n",
    "                'r', encoding='utf-8'))\n",
    "dfe = df1+df2\n",
    "with open('/148Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_extend_train_with_val.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(dfe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加1500条positive伪数据\n",
    "import json\n",
    "\n",
    "df1 = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_extend_train_with_val.json', \n",
    "                'r', encoding='utf-8'))\n",
    "df2 = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_train.json', \n",
    "                'r', encoding='utf-8'))\n",
    "df2 = df2[:1500]\n",
    "for sample in df2:\n",
    "    sample[\"source\"] = sample[\"target\"]\n",
    "    sample[\"type\"] = \"positive\"\n",
    "\n",
    "dfe = df1+df2\n",
    "with open('/148Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_extend_train_with_val_1500.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(dfe, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用初赛数据真实错误数据和决赛错误数据生成train_stage2.json\n",
    "# stage2\n",
    "import json\n",
    "\n",
    "df1 = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/final_train.json', \n",
    "                'r', encoding='utf-8'))\n",
    "df2 = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_extend_train.json', \n",
    "                'r', encoding='utf-8'))\n",
    "\n",
    "dfe = df1+df2\n",
    "with open('/148Dataset/data-tie.qianfeng/preliminary_a_data/final_train_stage2.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(dfe, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用初赛valid和决赛valid生成train_stage3.json\n",
    "# stage3\n",
    "import json\n",
    "\n",
    "df1 = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_val.json', \n",
    "                'r', encoding='utf-8'))\n",
    "df2 = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/final_val.json', \n",
    "                'r', encoding='utf-8'))\n",
    "\n",
    "dfe = df1+df2\n",
    "with open('/148Dataset/data-tie.qianfeng/preliminary_a_data/final_train_stage3.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(dfe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用初赛数据真实错误数据和决赛错误数据生成final_train_fusion_stage2_3.json\n",
    "import json\n",
    "df1 = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_val.json', \n",
    "                'r', encoding='utf-8'))\n",
    "df2 = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/final_val.json', \n",
    "                'r', encoding='utf-8'))\n",
    "df3 = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/final_train.json', \n",
    "                'r', encoding='utf-8'))\n",
    "df4 = json.load(open('/148Dataset/data-tie.qianfeng/preliminary_a_data/preliminary_extend_train.json', \n",
    "                'r', encoding='utf-8'))\n",
    "\n",
    "dfe = df1+df2+df3+df4\n",
    "with open('/148Dataset/data-tie.qianfeng/preliminary_a_data/final_train_fusion_stage2_3.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(dfe, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch19py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16fb356f935e542aa5f58aa71ff59ddf0054d7ac15a617e3de4aa7197e530308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
